---
description: 
globs: 
alwaysApply: true
---
	开始修改之前一定要先了解已有的数据库结构和文件结构，一定要在在现有项目基础上改动，不能自建简单文件测试
1.	封装与服务化规范
	•	如果检测到 Python 爬虫为脚本形式，将其封装为 Flask 或 FastAPI 的 Web 服务接口；
	•	要求该服务接口通过 HTTP POST 接收商品链接，并在后台运行爬虫；
	•	确保服务支持异步运行（如使用 threading 或 background task），不阻塞接口返回。
	2.	进度/评论实时反馈规范
	•	在爬虫运行过程中，每爬取一条评论或更新进度，应立即通过 WebSocket 或 SocketIO 将信息推送至前端；
	•	如果用户系统暂不支持 WebSocket，则提示可以使用 SSE（Server-Sent Events） 或 长轮询 作为替代；
	•	可以在爬虫端提供一个标准格式的 emit_update 函数或中间件，统一输出。
	3.	数据库规范
	•	每获取一条评论后，立即写入数据库，而不是等全部评论爬完后一次性批量写入；
	•	如果商品名尚未存在于 product 表中，需先插入并获取其 ID；
	•	插入评论时，将其与对应商品的 product_id 外键正确关联；
	•	推荐使用 SQLAlchemy 或封装好的插入函数，避免 SQL 注入问题；
	•	加入唯一性判断，防止重复评论插入（如根据评论内容 + 用户 + 时间进行去重）。
	4.	Java 后端调用规范
	•	指导用户通过 Java 后端（Spring Boot 或原生 Servlet）使用 HttpClient 向 Python 提供的爬虫接口发送 POST 请求；
	•	请求体包含商品链接等参数；
	•	如果系统希望直接运行 Python 脚本，则使用 ProcessBuilder 并监听 InputStream 获取运行过程中的输出，实时转发至前端；
	•	要求后端具有异常捕获与爬虫状态监控机制。
	5.	前端展示规范
	•	建议前端使用 WebSocket 建立与后端（或 Python 爬虫服务）的连接；
	•	实时接收评论/进度更新并以列表或滚动形式显示；
	•	若使用轮询方案，应设定合理轮询间隔（建议 2 秒）；
	•	前端样式应提供清晰的“当前爬取商品名”“已获取 X 条评论”等提示。
	6.	系统解耦与拓展性规范
	•	鼓励将爬虫、数据入库、前端展示分别解耦成模块，提升维护性；
	•	后期可以通过任务队列（如 Celery、Redis）进一步优化并发与状态管理；
	•	明确模块边界：前端负责显示、Java 后端负责调度、Python 爬虫专注数据获取。